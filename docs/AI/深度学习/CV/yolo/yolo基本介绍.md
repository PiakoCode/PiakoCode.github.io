# yoloV5基本介绍



执行yolo v5

```shell
python detect.py
```

**非极大值抑制 NMS**

https://zhuanlan.zhihu.com/p/78504109



YOLO的构成可以分为三个主要部分：特征提取网络、感兴趣区域（Region of Interest，ROI）划分和预测。

1. 特征提取网络： YOLO使用深度卷积神经网络（Convolutional Neural Network，CNN）作为特征提取网络。通常情况下，采用已经在大规模图像数据集上预训练好的CNN模型，例如VGGNet或DarkNet作为特征提取器。这些模型能够学习到图像的高级特征表示。
    
2. 感兴趣区域（Region of Interest，ROI）划分： 在特征图上，YOLO将图像分成一个固定大小的网格单元。每个网格单元负责检测该单元中物体的位置和类别。对于每个网格单元，YOLO会预测一个边界框（bounding box），即包围物体的矩形框，并输出框内物体的类别概率。
    
3. 预测： 对于每个网格单元，YOLO预测边界框的坐标以及每个边界框中包含的物体类别的概率。这些预测值通过卷积和全连接层来生成。YOLO使用单个卷积层来同时预测边界框的位置和类别概率，并在最后一层使用非线性激活函数（如sigmoid）将坐标限制在图像范围内。

![](Picture/Pasted%20image%2020230831162436.png)
## 预测阶段(前向推断)

1. 输入图像被分割成一个固定大小的网格（例如，将图像划分为 S × S 的网格，每个格子大小为 W × H）。

2. 对每个格子，预测多个边界框（bounding boxes）以及这些边界框中包含的目标的类别概率。每个边界框通常由 5 个参数描述：x、y（边界框的中心坐标）、w、h（边界框的宽度和高度）以及一个置信度分数。

3. 对每个格子中的边界框进行筛选，根据置信度分数进行阈值过滤，只保留置信度高于预设阈值的边界框。

4. 使用非极大值抑制（non-maximum suppression，NMS）进一步处理，去除冗余的边界框。NMS 会计算边界框之间的重叠度，并保留具有最高置信度的边界框，同时删除与其高重叠度的其他边界框。

5. 最后得到的边界框即为模型预测的目标位置和类别。

整个过程是端到端的，即一次前向推断即可得到目标检测结果。YOLO 的优势在于其实时性和较高的准确率，但也由于固定网格的划分方式，可能对小尺寸目标的检测效果较差。


## 预测阶段(后处理)

1. 先验框解码：在训练阶段，YOLOv1通过对训练集进行聚类分析，得到一组先验框（anchor boxes），这些先验框代表了不同尺度和长宽比的目标。在预测阶段，先验框需要被解码，将其转换为实际图像上的边界框。

2. 类别概率计算：对于每个先验框，YOLOv1会预测出多个类别的概率。这些概率需要通过softmax函数进行归一化，以得到每个类别的预测概率。

3. 边界框筛选：由于YOLOv1在图像上使用了网格划分，每个网格预测出的边界框可能会有重叠。为了避免重复的检测结果，需要进行非最大抑制（Non-Maximum Suppression）来筛选边界框。非最大抑制的目标是选择置信度最高的边界框，并且排除掉与其IoU（交并比）大于一定阈值的其他边界框。

4. 边界框调整：在非最大抑制之后，最终的边界框需要进行调整，以适应原始图像上的目标位置。这一步骤通常涉及到对边界框的平移、缩放和裁剪等操作。

***

1. 对于每个网格单元，根据预测的边界框的置信度（confidence）进行阈值筛选，剔除置信度较低的边界框。

2. 对于剩余的边界框，使用非极大值抑制（Non-maximum Suppression，NMS）算法进行重叠边界框的合并。NMS算法会根据重叠度（IoU）将重叠较高的边界框合并为一个，并选择置信度最高的边界框作为最终的检测结果。

3. 最后，根据置信度的阈值再次筛选出置信度高于阈值的边界框，作为最终的检测结果。

**yolov1中的预处理阶段,一格产生多少个bounding box,为什么?**

在YOLOv1中的预处理阶段，每个单元格（grid cell）产生的bounding box的数量由两个因素决定：先验框（prior box）的数量和每个单元格预测的类别数。

首先，YOLOv1将输入图像划分为S × S个单元格，其中S是预定义的网格大小。对于每个单元格，模型将预测B个bounding box，其中B是先验框的数量。

其次，每个bounding box预测一个边界框的位置和置信度分数，以及C个类别的概率分布，其中C是模型需要分类的类别数。因此，每个bounding box的预测输出包括4个边界框坐标、一个置信度分数和C个类别的概率分布，总共有5 + C个预测值。

因此，每个单元格将生成B个bounding box，每个bounding box都有5 + C个预测值，这就是为什么每个单元格会产生多个bounding box的原因。这样设计的目的是为了捕捉不同尺度和不同类别的目标物体。

### NMS 非极大值抑制

在目标检测任务中，一张图像可能会生成多个重叠的边界框，每个边界框都表示一个可能的物体。为了消除重叠边界框并选择最佳的边界框，NMS被应用于YoloV1的输出。

NMS的工作原理如下：
1. 对于每个类别的边界框，根据置信度排序。
2. 选择置信度最高的边界框，将其添加到最终输出列表中。
3. 对于剩余的边界框，计算它们与已选择的边界框的重叠程度（如IoU）。
4. 如果重叠程度超过了一定的阈值，则将该边界框丢弃。
5. 重复步骤2-4，直到所有边界框都被处理完。

>IOU Intersection over Union（交并比）两个框的交集面积/并集面积


## 训练阶段(反向传播)


损失函数:
![](Picture/Pasted%20image%2020230831192039.png)


$$
\mathcal{L}_{\text{YOLO}} = \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{{ij}}^{\text{obj}} \left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right] \\
+ \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{{ij}}^{\text{obj}} \left[ (\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2 \right] \\
+ \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{{ij}}^{\text{obj}} (C_i - \hat{C}_i)^2 \\
+ \lambda_{\text{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{{ij}}^{\text{noobj}} (C_i - \hat{C}_i)^2 \\
+ \sum_{i=0}^{S^2} \mathbb{1}_{{i}}^{\text{obj}} \sum_{c \in \text{classes}} (p_i(c) - \hat{p}_i(c))^2
$$

其中，$S$表示输入图像被划分的格子数量，$B$表示每个格子生成的边界框数量，$\lambda_{\text{coord}}$和$\lambda_{\text{noobj}}$是调节坐标损失和背景损失的权重。$\mathbb{1}_{{ij}}^{\text{obj}}$和$\mathbb{1}_{{ij}}^{\text{noobj}}$分别表示第$i$个格子中第$j$个边界框是否含有目标和是否不含有目标。$x_i, y_i, w_i, h_i$是第$i$个格子中第$j$个边界框的中心坐标和宽高，$C_i$是第$i$个格子中第$j$个边界框是否含有目标的置信度，$p_i(c)$是第$i$个格子中第$j$个边界框属于类别$c$的概率。

$\hat{x}_i, \hat{y}_i, \hat{w}_i, \hat{h}_i$是预测值，$\hat{C}_i$是目标值，$\hat{p}_i(c)$是真实类别$c$的概率。

损失函数包括坐标损失、置信度损失和类别损失。坐标损失衡量预测的边界框与真实边界框的中心坐标和宽高之间的差异。置信度损失衡量预测的边界框是否含有目标的准确度。类别损失衡量预测的边界框所属类别的准确度。

其损失函数是由多个部分组成的。主要包括三个部分：

1. 目标定位损失（Localization Loss）：用于衡量预测框的位置准确程度。一般使用平方差损失（如L2损失）或Huber损失函数。

2. 目标置信度损失（Confidence Loss）：用于衡量预测框是否包含目标物体以及框的置信度准确程度。一般使用二分类损失函数，如交叉熵损失函数。

3. 无目标框损失（No-Object Loss）：用于衡量预测框中没有目标的部分的准确程度。一般使用二分类损失函数。

具体的损失函数为：
总损失 = 目标定位损失 + 目标置信度损失 + 无目标框损失
